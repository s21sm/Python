{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Positioning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeWjdRpmRZXxoKXn9vWyy+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s21sm/Python/blob/master/CNN_Positioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dwAuVHRHxKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This program is used for CNN based RF fingerprinting positioning calculation\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from scipy.spatial import distance\n",
        "import time\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "link1 = 'https://drive.google.com/open?id=1fMPzxJ1rjzoAHCrAEZwMgJFnuelq1f6l' # training rss\n",
        "link2 = 'https://drive.google.com/open?id=1_3oR_DmfO4MUVkjzmiPp4ze8ZVd9lQYH' # test rss\n",
        "link3 = 'https://drive.google.com/open?id=1oqe9BmyMy994z0TgUsIzujIcRhbjd7N4' # train coordinte\n",
        "link4 = 'https://drive.google.com/open?id=1w7ym-3OtIDNLSvSS3HI3VKJCcxR4zeZc' # test coordinate\n",
        "\n",
        "fluff, id = link1.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Training_rss_21Aug17.csv')  \n",
        "df1 = pd.read_csv('Training_rss_21Aug17.csv')\n",
        "train_rss = np.array(df1)\n",
        "train_rss = np.delete(train_rss, 620, 0) # errornious training FP\n",
        "\n",
        "\n",
        "fluff, id = link2.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Test_rss_21Aug17.csv')  \n",
        "df2 = pd.read_csv('Test_rss_21Aug17.csv')\n",
        "test_rss = np.array(df2)\n",
        "err_test = [1267, 2066, 2192, 3084, 3487, 3542] # errornious test FP\n",
        "test_rss = np.delete(test_rss,err_test,0)\n",
        "\n",
        "\n",
        "\n",
        "fluff, id = link3.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Training_coordinates_21Aug17.csv')  \n",
        "df3 = pd.read_csv('Training_coordinates_21Aug17.csv')\n",
        "train_coordinate = np.array(df3)\n",
        "train_coordinate = np.delete(train_coordinate, 620, 0)\n",
        "\n",
        "\n",
        "\n",
        "fluff, id = link4.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Test_coordinates_21Aug17.csv')  \n",
        "df4 = pd.read_csv('Test_coordinates_21Aug17.csv')\n",
        "test_coordinate = np.array(df4)\n",
        "err_test = [1267, 2066, 2192, 3084, 3487, 3542]\n",
        "test_coordinate = np.delete(test_coordinate,err_test,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHNS2BUtNJWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# floor mapping 0 = 0, 3.7 = 1, 7.4 = 2 ........\n",
        "def floor_mapping(coordinate):\n",
        "  floors = coordinate[:,2]\n",
        "  mapp =[]\n",
        "  for i in range(floors.shape[0]):\n",
        "    if floors[i] == 0.0:\n",
        "      mapp.append(0)\n",
        "    elif floors[i] == 3.7:\n",
        "      mapp.append(1)\n",
        "    elif floors[i] == 7.4:\n",
        "      mapp.append(2)\n",
        "    elif floors[i] == 11.1:\n",
        "      mapp.append(3)\n",
        "    elif floors[i] == 14.8:\n",
        "      mapp.append(4)\n",
        "  floors = np.asarray(mapp)\n",
        "  return floors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8vjFt1J5rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Floor \n",
        "train_floors = floor_mapping(train_coordinate)\n",
        "test_floors = floor_mapping(test_coordinate)\n",
        "# categorical floor\n",
        "train_floors = np.array(keras.utils.to_categorical(train_floors,num_classes=5))\n",
        "test_floors = np.array(keras.utils.to_categorical(test_floors,num_classes=5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ovlypeVHFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_rss=np.hstack([train_rss, np.full((695, 32), 100)])\n",
        "# For training data : changing the initial RSS value 100 to -103\n",
        "for i in range(train_rss.shape[0]): \n",
        " for j in range(train_rss.shape[1]):\n",
        "  if train_rss[i,j] == 100:\n",
        "    train_rss[i,j] = -103\n",
        "  elif train_rss[i,j] > -30:\n",
        "    train_rss[i,j] = -30\n",
        "\n",
        "# normalization\n",
        "train_rss_normal=np.zeros((695, 1024))\n",
        "for i in range(train_rss.shape[0]): \n",
        " for j in range(train_rss.shape[1]):\n",
        "   train_rss_normal[i,j] = ((train_rss[i,j] + 103)/ 73 ) \n",
        "\n",
        "\n",
        "test_rss=np.hstack([test_rss, np.full((3944, 32), 100)])\n",
        "# For test data : changing the initial RSS value 100 to -103\n",
        "for i in range(test_rss.shape[0]): \n",
        " for j in range(test_rss.shape[1]):\n",
        "  if test_rss[i,j] == 100:\n",
        "    test_rss[i,j] = -103\n",
        "  elif test_rss[i,j] > -30:\n",
        "    test_rss[i,j] = -30\n",
        "\n",
        "# normalization\n",
        "test_rss_normal=np.zeros((3944, 1024))\n",
        "for i in range(test_rss.shape[0]): \n",
        " for j in range(test_rss.shape[1]):\n",
        "   test_rss_normal[i,j] = ((test_rss[i,j] + 103)/ 73) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyfMHfwBVcgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating fingerprint image\n",
        "train_rss_pixel = np.reshape(train_rss_normal, (-1, 32, 32))\n",
        "test_rss_pixel = np.reshape(test_rss_normal, (-1, 32, 32))\n",
        "\n",
        "x_train = np.reshape (train_rss_pixel, list (np.shape (train_rss_pixel)) + [1])\n",
        "x_test = np.reshape (test_rss_pixel, list (np.shape (test_rss_pixel)) + [1])\n",
        "y_train = train_floors\n",
        "y_test = test_floors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LllLxAVnWC8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Floor detection model\n",
        "floor_result_box =[]\n",
        "for p in range(20):\n",
        "  floor_model = Sequential()\n",
        "  floor_model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(32,32,1)))\n",
        "  floor_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  floor_model.add(Flatten())\n",
        "  floor_model.add(Dense(100))\n",
        "  floor_model.add(Dropout(0.7))\n",
        "  floor_model.add(Dense(5))\n",
        "  floor_model.add(Activation('softmax'))\n",
        "  floor_model.compile(loss='categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
        "  floor_model.fit(x_train,y_train,epochs=30)\n",
        "  a = floor_model.evaluate(x_test,y_test)\n",
        "  floor_result_box.append(a[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBM_KbZjX6dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lebeling for positioning model, each training fingerprint is a lebel\n",
        "training_coordinate_label = np.arange(695)\n",
        "y_train_all = keras.utils.to_categorical(training_coordinate_label,num_classes=695)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjo0WHUacW1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for 3D positioning model\n",
        "result_box =[]\n",
        "for k in range(20):\n",
        "  positioning_model = Sequential()\n",
        "  positioning_model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(32,32,1)))\n",
        "  positioning_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  positioning_model.add(Flatten())\n",
        "  positioning_model.add(Dense(1024))\n",
        "  #positioning_model.add(Dropout(0.7))\n",
        "  positioning_model.add(Dense(695))\n",
        "  positioning_model.add(Activation('softmax'))\n",
        "  positioning_model.compile(loss='categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
        "  positioning_model.fit(x_train,y_train_all,epochs=30)\n",
        "\n",
        "  posi_error = 0\n",
        "  floor_error = 0\n",
        "  needed_time = 0\n",
        "  for i in range(3944): \n",
        "     start_time = time.time()\n",
        "     prediction =  positioning_model.predict(x_test[i].reshape(1, 32, 32, 1)) # for specific images\n",
        "     pre = np.argmax(prediction)\n",
        "     a = train_coordinate[pre]\n",
        "     end_time=time.time()\n",
        "     time_diff = (end_time-start_time)\n",
        "     needed_time += time_diff\n",
        "     b = test_coordinate[i]\n",
        "     x=distance.euclidean(a,b)\n",
        "     posi_error+= x\n",
        "     if a[2] == b[2]:\n",
        "       floor_error+=1\n",
        "  x1 = posi_error/3945\n",
        "  x2 = floor_error/3945\n",
        "  x3 = needed_time/3945\n",
        "  line=[x1,x2,x3]\n",
        "  print(line)\n",
        "  result_box.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}